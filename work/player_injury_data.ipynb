{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Player Injury Data\n",
    "I scraped all player injury data from TSN.ca's player profiles. In order to find the URLs for each player profile I first scraped the main TSN player page for links to every available profile. I then iterated through each profile to scrape the section containing injury, transaction, and suspension data. I finally converted the list of profile data into a DataFrame, removed non-injury events, and parsed reports for length and type of injury. I utilized Selenium for scraping because both the TSN player menu and profile pages use Javascript to populate their table data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [1. Imports and Functions](#sec1)\n",
    "* [2. Create a Shared Webdriver](#sec2)\n",
    "* [3. Scrape Player Profile Links](#sec3)\n",
    "* [4. Scrape Each Player Profile](#sec4)\n",
    "* [5. Convert List of Profiles to DataFrames](#sec5)\n",
    "* [6. Cleanup](#sec6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec1'></a>\n",
    "### 1. Imports and Functions\n",
    "Most of my code is stored in nhl_injuries_code.py so that it can easily be used across notebooks. This notebook utilizes the following functions from that file:\n",
    "* **read_profile_links**: Scrapes all player profile links from TSN.ca's main player page\n",
    "* **read_player_profile**: Scrapes a player's injury, transaction, and suspension history from TSN.ca\n",
    "* **profiles_to_dfs**: Converts a list of player profiles into a DataFrame containing just injury data\n",
    "* **var_to_pickle**: Writes the given variable to a pickle file\n",
    "* **read_pickle**: Reads the given pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from nhl_injuries_code import (read_profile_links,\n",
    "                               read_player_profile,\n",
    "                               profiles_to_dfs,\n",
    "                               var_to_pickle,\n",
    "                               read_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2'></a>\n",
    "### 2. Create a Shared Webdriver\n",
    "In the interest of efficiency, all functions use the same webdriver since they simply run in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = \"/Applications/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3'></a>\n",
    "### 3. Scrape Player Profile Links\n",
    "Scraping all links takes around 30 seconds, but the list of links gets loaded from a pickle if the pickle exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_pickle = 'pickle_data/player_links.pk'\n",
    "links = read_pickle(links_pickle)\n",
    "if links == None:\n",
    "    links = read_profile_links(driver)\n",
    "    var_to_pickle(links, links_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec4'></a>\n",
    "### 4. Scrape Each Player Profile\n",
    "**Warning**: Scraping all profiles takes around 3 hours. If a pickle exists, the code below will use it as a starting point and then scrape the remaining data, or simply use the pickle if it contains all profile data. If scraping is required, the pickle gets updated automatically every **save_step** profiles scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_pickle = 'pickle_data/player_profiles.pk'\n",
    "bio_url = 'https://www.tsn.ca%s/bio'\n",
    "save_step = 50\n",
    "\n",
    "# Loads data from pickle if it exists, otherwise scrapes it\n",
    "profiles = read_pickle(profiles_pickle)\n",
    "if profiles == None:\n",
    "    profiles = []\n",
    "    \n",
    "# If pickle data is not complete, picks up where it left off\n",
    "start = len(profiles)\n",
    "if start < len(links):\n",
    "    for cnt,link in enumerate(links[start:]):\n",
    "        profiles.append(read_player_profile(driver, bio_url % link))\n",
    "        if (cnt+1) % save_step == 0:\n",
    "            var_to_pickle(profiles, profiles_pickle)\n",
    "    var_to_pickle(profiles, profiles_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec5'></a>\n",
    "### 5. Convert List of Profiles to DataFrames\n",
    "* **names_df**: player name data with columns [Name, Birth_Date]\n",
    "* **injuries_df**: player injury data with columns [Name, Birth_Date, Injury_Date, Report, Games_Missed, Cause]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df, injuries_df = profiles_to_dfs(profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec6'></a>\n",
    "### 6. Cleanup\n",
    "Quits the shared webdriver and saves pickles of the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n",
    "names_pickle = '../data/names_df.pk'\n",
    "injuries_pickle = '../data/injuries_df.pk'\n",
    "var_to_pickle(names_df, names_pickle)\n",
    "var_to_pickle(injuries_df, injuries_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
