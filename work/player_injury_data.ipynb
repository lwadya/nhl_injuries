{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Player Injury Data\n",
    "I scraped all player injury data from TSN.ca's player profiles. In order to find the URLs for each player profile I first scraped the main TSN player page for links to every available profile. I then iterated through each profile to scrape the section containing injury, transaction, and suspension data. I finally converted the list of profile data into a DataFrame, removed non-injury events, and parsed reports for length and type of injury. I utilized Selenium for scraping because both the TSN player menu and profile pages use Javascript to populate their table data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping and Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_profile_links(driver):\n",
    "    '''Reads all player profile links from TSN.ca's main player page\n",
    "    \n",
    "    Args:\n",
    "        driver (selenium webdriver): a valid webdriver\n",
    "        \n",
    "    Returns:\n",
    "        list: player profile URLs\n",
    "    '''\n",
    "    main_url = 'https://www.tsn.ca/nhl/players'\n",
    "    link_pattern = '/nhl/player-bio/[^\"]+'\n",
    "    disabled_class = 'ng-scope disabled'\n",
    "    \n",
    "    # Iterates through all pages of player profile links\n",
    "    driver.get(main_url)\n",
    "    links = []\n",
    "    while True:\n",
    "        links.extend(re.findall(link_pattern, driver.page_source))\n",
    "        next_button = driver.find_element_by_css_selector('a.next.ng-scope')\n",
    "        if next_button.find_element_by_xpath('..').get_attribute('class') == disabled_class:\n",
    "            break\n",
    "        next_button.click()\n",
    "        \n",
    "    return links\n",
    "\n",
    "def read_player_profile(driver, player_url):\n",
    "    '''Reads a player's injury, transaction, and suspension history from TSN.ca\n",
    "    \n",
    "    Args:\n",
    "        driver (selenium webdriver): a valid webdriver\n",
    "        player_url (str): url that contains player profile data\n",
    "        \n",
    "    Returns:\n",
    "        list: player event data as a list of lists, each nested list containing\n",
    "              [player name, birth date, date, event description]\n",
    "    '''\n",
    "    driver.get(player_url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    roster_updates = []\n",
    "    \n",
    "    # Player Name is stored in list items with specific classes\n",
    "    first_name = soup.find('li', {'class':'first-name ng-binding'}).text\n",
    "    last_name = soup.find('li', {'class':'last-name ng-binding'}).text\n",
    "    player_name = f'{first_name} {last_name}'\n",
    "    \n",
    "    # Birth Date is stored in a span with a specific class\n",
    "    birth_date = soup.find('span', {'class':'value-desc ng-binding'}).text\n",
    "    \n",
    "    # Date and Event are stored in two spans under 'tr' tags with specific 'ng-repeat' values\n",
    "    rows = soup.find_all('tr', {'ng-repeat':'rosterMoves in PlayerBio.RosterMoves'})\n",
    "    for row in rows:\n",
    "        spans = row.find_all('span')\n",
    "        update = [span.text for span in spans]\n",
    "        if update:\n",
    "            roster_updates.append([player_name, birth_date] + update)\n",
    "            \n",
    "    return roster_updates\n",
    "\n",
    "def profiles_to_dfs(player_profiles):\n",
    "    '''Converts a list of player profiles into a DataFrame containing just injury data\n",
    "    \n",
    "    Args:\n",
    "        player_urls (str list): nested lists of individual player profiles\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: player name data with columns [Name, Birth_Date]\n",
    "        DataFrame: player injury data with columns\n",
    "                   [Name, Birth_Date, Date, Report, Games_Missed, Cause]\n",
    "    '''\n",
    "    columns = ['Name', 'Birth_Date', 'Date', 'Report']\n",
    "    df = pd.DataFrame(list(itertools.chain(*player_profiles)), columns=columns)\n",
    "    names_df = df[columns[:2]].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Use a mask to isolate reports of missed games and ignore suspensions\n",
    "    df['Report'] = df['Report'].str.lower()\n",
    "    report_mask = ((df['Report'].str.contains('missed \\d* game')) &\n",
    "                   ~(df['Report'].str.contains('suspen')))\n",
    "    df = df[report_mask].reset_index(drop=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%b %d, %Y')\n",
    "    \n",
    "    # Assume the number of missed games is the only numerical data in reports\n",
    "    df['Missed'] = df['Report'].str.replace('\\D', '')\n",
    "    # Cause of missed games is everything between parentheses\n",
    "    df['Cause'] = df['Report'].str.findall('(?<=\\().*(?=\\))').str.join('')\n",
    "    \n",
    "    return names_df, df\n",
    "\n",
    "def var_to_pickle(var, filename):\n",
    "    '''Writes the given variable to a pickle file\n",
    "    \n",
    "    Args:\n",
    "        var (any): variable to be written to pickle file\n",
    "        filename (str): path and filename of pickle file\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    try:\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(var, f)\n",
    "    except:\n",
    "        print(f'Failed to save pickle to \\'{filename}\\'')\n",
    "    return\n",
    "\n",
    "def read_pickle(filename):\n",
    "    '''Reads the given pickle file\n",
    "    \n",
    "    Args:\n",
    "        filename (str): path and filename of pickle file\n",
    "    \n",
    "    Returns:\n",
    "        any: contents of pickle file if it exists, None if not\n",
    "    '''\n",
    "    output = None\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                output = pickle.load(f)\n",
    "        except:\n",
    "            print(f'Failed to load pickle from \\'{filename}\\'')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Single, Shared Webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Player Profile Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_pickle = 'pickle_data/player_links.pickle'\n",
    "links = read_pickle(links_pickle)\n",
    "if links == None:\n",
    "    links = read_profile_links(driver)\n",
    "    var_to_pickle(links, links_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Each Player Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-38663801dd61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprofiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_player_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbio_url\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msave_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mvar_to_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiles_pickle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-176-e0275329b19f>\u001b[0m in \u001b[0;36mread_player_profile\u001b[0;34m(driver, player_url)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Player Name is stored in list items with specific classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mfirst_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'li'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'first-name ng-binding'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mlast_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'li'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'last-name ng-binding'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mplayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{first_name} {last_name}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "profiles_pickle = 'pickle_data/player_profiles.pickle'\n",
    "bio_url = 'https://www.tsn.ca%s/bio'\n",
    "save_step = 50\n",
    "\n",
    "# Loads data from pickle if it exists, otherwise scrapes it\n",
    "profiles = read_pickle(profiles_pickle)\n",
    "if profiles == None:\n",
    "    profiles = []\n",
    "    \n",
    "# If pickle data is not complete, picks up where it left off\n",
    "start = len(profiles)\n",
    "if start < len(links):\n",
    "    for cnt,link in enumerate(links[start:]):\n",
    "        profiles.append(read_player_profile(driver, bio_url % link))\n",
    "        if (cnt+1) % save_step == 0:\n",
    "            var_to_pickle(profiles, profiles_pickle)\n",
    "    var_to_pickle(profiles, profiles_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Profiles to Injury DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df, injuries_df = profiles_to_dfs(profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quit Webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
